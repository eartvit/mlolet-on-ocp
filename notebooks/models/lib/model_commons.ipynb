{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df859262-c5b7-4c5c-8c38-cc76c294a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <update with the URL of your MLFLOW instance>\n",
    "MLFLOW_URI='http://localhost:8080/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b745669-8a30-4d26-ada7-c630f540dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space={\n",
    "    \"n_epochs\": tune.choice([200]),\n",
    "    \"n_layers\": tune.choice([1, 3, 5, 10]),\n",
    "    \"n_dense_layers\": tune.choice([1, 3, 5]), \n",
    "    \"learning_rate\": tune.choice([0.003, 0.001]),\n",
    "    \"activation\": tune.choice(['tanh', 'relu']), \n",
    "    \"conv_kernel\": tune.choice([2, 3]),\n",
    "    \"n_neurons\": tune.choice([32, 64, 96, 128, 256]),\n",
    "    \"T\": tune.choice([5, 10, 15, 20]),\n",
    "    \"dense_dp\": tune.choice([0.2, 0.3, 0.4]),\n",
    "    \"DP\": tune.choice([0, 0.2, 0.4]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82059ec5-d533-49b1-9f43-bcbed2ad285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " This function uses one Tensor formatted input from the X_test dataset in order to predict ahead by a number\n",
    " of given steps. Then it readjusts by using another true value from X_test (as the nex index) before starting\n",
    " a new prediction cycle\n",
    "\"\"\"\n",
    "def generate_nsteps_forecast(x_test, y_test, nn_model, pred_ahead):\n",
    "    max_len = x_test.shape[0]\n",
    "    y_pred = []\n",
    "    last_x = x_test[0]\n",
    "    index = 0\n",
    "    ae_errors_at_p = []\n",
    "    se_errors_at_p = []\n",
    "    while len(y_pred) < max_len:\n",
    "        sequence = 0\n",
    "        while sequence < pred_ahead:\n",
    "            try:\n",
    "                x_crt_input = last_x.reshape(1, -1, 1)\n",
    "                p_vector = nn_model.predict(x_crt_input, verbose=0)\n",
    "                p = p_vector[0,0] # 1x1 array -> scalar\n",
    "            except:\n",
    "                print(f'Prediction error for x={x_crt_input} at sequence={sequence} for start index={index} when pred_ahead={pred_ahead}')\n",
    "                print(f'Model config was:{nn_model.get_config()}')\n",
    "                p = 0\n",
    "                \n",
    "            # update the predictions list\n",
    "            y_pred.append(p)\n",
    "\n",
    "            # make the new input\n",
    "            last_x = np.roll(last_x, -1)\n",
    "            last_x[-1] = p\n",
    "            \n",
    "            # increase index for the next run\n",
    "            sequence += 1\n",
    "\n",
    "        index += sequence\n",
    "        \n",
    "        if index < max_len:\n",
    "            last_x = x_test[index]\n",
    "            ae_errors_at_p.append(np.absolute(p - y_test[index-1]))\n",
    "            se_errors_at_p.append(np.square(p - y_test[index-1]))\n",
    "            #print(f\"Arrived at index = {index} of {max_len} with value X={last_x}\")\n",
    "    \n",
    "    if len(y_pred) > max_len:\n",
    "        # predicted too much, cutoff the tail\n",
    "        y_pred = y_pred[0:max_len]\n",
    "\n",
    "    y_pred_array = np.array(y_pred)\n",
    "    avg_ae = np.mean(ae_errors_at_p)\n",
    "    avg_se = np.mean(se_errors_at_p)\n",
    "    return (y_pred_array, avg_ae, avg_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fbbe04-9c3d-4658-8a1e-1d75af2cdb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "\n",
    "    n_neurons = config['n_neurons']\n",
    "    n_epochs = config['n_epochs']\n",
    "    learning_rate = config['learning_rate']\n",
    "    T = config['T']\n",
    "\n",
    "    model_exp =  f'{modelTypeName}'\n",
    "    UUID = uuid.uuid4().hex\n",
    "\n",
    "    mlflow_exp_name = f'{modelTypeName}-{UUID}-T_{T}-LY_{config[\"n_layers\"]}-DLY_{config[\"n_dense_layers\"]}-NN_{n_neurons}'\n",
    "\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "    mlflow.set_registry_uri(MLFLOW_URI)\n",
    "        \n",
    "    nn_model = create_model(config)\n",
    "    nn_model.compile(loss='mse', \n",
    "                     metrics=[\"mse\"], \n",
    "                     #metrics=\"mse\", #tf 2.11-2.13\n",
    "                     optimizer=Adam(learning_rate=config[\"learning_rate\"]))\n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = prepare_dataset(dataFrame[dataColumnName], T)\n",
    "    \n",
    "    model_name = modelTypeName + \"-T_\" + str(T) + \"-LY_\" + str(config['n_layers']) + \"-DLY_\" + str(config['n_dense_layers']) +\\\n",
    "                 \"-NN_\" + str(n_neurons) + \"-LR_\" + str(learning_rate) + \"-epochs_\" + str(n_epochs) +\"-\" + UUID + \".keras\"\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=5)\n",
    "    mc = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True)    \n",
    "    \n",
    "    train_results = nn_model.fit(X_train, Y_train, \n",
    "                                 epochs=config['n_epochs'], \n",
    "                                 validation_data=(X_test, Y_test), \n",
    "                                 #callbacks=[ReportCheckpointCallback(metrics={\"mse\": \"mse\"}, checkpoint_on=\"train_end\")],\n",
    "                                 callbacks=[es, mc],\n",
    "                                 verbose = 0\n",
    "                                )\n",
    "    \n",
    "    #evaluate and print results\n",
    "    try:\n",
    "        saved_model = load_model(model_name)\n",
    "    except:\n",
    "        saved_model = nn_model\n",
    "        save_model(nn_model, model_name)\n",
    "\n",
    "    # Reconstruct signal using the train data and get the AE and SE errors to obtain the 3-sigma thresholds\n",
    "    y_pred_train = saved_model.predict(X_train, verbose=0)\n",
    "    \n",
    "    errors_ae_train = calculate_absolute_prediction_errors(Y_train, y_pred_train)\n",
    "    lo_3sigma_ae, up_3sigma_ae = calculate_3sigma_threshold(errors_ae_train)\n",
    "    anomalies_ae_train = calculate_3sigma_anomalies(errors_ae_train, lo_3sigma_ae, up_3sigma_ae)\n",
    "    \n",
    "    errors_se_train = calculate_squared_prediction_errors(Y_train, y_pred_train)\n",
    "    lo_3sigma_se, up_3sigma_se = calculate_3sigma_threshold(errors_se_train)\n",
    "    anomalies_se_train = calculate_3sigma_anomalies(errors_se_train, lo_3sigma_se, up_3sigma_se)\n",
    "\n",
    "    three_sigma_thresholds = {}\n",
    "    three_sigma_thresholds['lo_3sigma_ae'] = lo_3sigma_ae\n",
    "    three_sigma_thresholds['up_3sigma_ae'] = up_3sigma_ae\n",
    "    three_sigma_thresholds['lo_3sigma_se'] = lo_3sigma_se\n",
    "    three_sigma_thresholds['up_3sigma_se'] = up_3sigma_se\n",
    "    \n",
    "    # Test spike detection using 3-sigma rule on the test data\n",
    "    y_predict = saved_model.predict(X_test, verbose=0)\n",
    "    errors_ae = calculate_absolute_prediction_errors(Y_test, y_predict)\n",
    "    anomalies_ae = calculate_3sigma_anomalies(errors_ae, lo_3sigma_ae, up_3sigma_ae)\n",
    "    errors_se = calculate_squared_prediction_errors(Y_test, y_predict)\n",
    "    anomalies_se = calculate_3sigma_anomalies(errors_se, lo_3sigma_se, up_3sigma_se)\n",
    "    \n",
    "    try:\n",
    "        r2 = r2_score(Y_test, y_predict)\n",
    "    except:\n",
    "        r2 = 110\n",
    "    if np.isnan(r2):\n",
    "        r2 = 110\n",
    "\n",
    "    try:\n",
    "        mae = mean_absolute_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mae = 100\n",
    "    if np.isnan(mae):\n",
    "        mae = 100\n",
    "\n",
    "    try:\n",
    "        mape = mean_absolute_percentage_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mape = 100\n",
    "    if np.isnan(mape):\n",
    "        mape = 100\n",
    "\n",
    "    try:\n",
    "        mse = mean_squared_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mse = 100\n",
    "    if np.isnan(mse):\n",
    "        mse = 100\n",
    "    \n",
    "    try:\n",
    "        pcc = np.corrcoef(Y_test, y_predict.flatten())[0,1]\n",
    "    except:\n",
    "        pcc = 100\n",
    "    if np.isnan(pcc):\n",
    "        pcc = 100\n",
    "\n",
    "    experiment_id = mlflow.create_experiment(mlflow_exp_name)\n",
    "    with mlflow.start_run(run_name=mlflow_exp_name, experiment_id=experiment_id) as mlflowrun:\n",
    "        run_id = mlflowrun.info.run_id\n",
    "\n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        plt.title(\"Spikes Train Data\")\n",
    "        plt.plot(Y_train,label=\"Original Data\", alpha=0.6, c='gray')\n",
    "        plt.plot(y_pred_train,label=\"Predict 1-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "        plt.scatter(np.where(anomalies_ae_train==True), y_pred_train[np.where(anomalies_ae_train==True)], \n",
    "                    alpha=0.8, color='green', s=350, label=\"3-Sigma Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_se_train==True), y_pred_train[np.where(anomalies_se_train==True)], \n",
    "                    alpha=0.8, color='magenta', s=150, label=\"3-Sigma Anomalies SE\")\n",
    "        plt.legend()\n",
    "        figName = f\"Y_train_spikes-T_{T}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        #plt.savefig(figName, transparent=False)\n",
    "        fig.clf()\n",
    "        plt.close()\n",
    "    \n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        plt.title(\"Spikes Test Data T=\" + str(T) + \" with predict 1 on \"+ str(model_exp) +\": NN=\" + str(n_neurons) + \" epochs=\" + str(n_epochs) +\n",
    "                  \" lr=\" + str(learning_rate))\n",
    "        plt.plot(y_predict,label=\"Predict 1-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='black')\n",
    "        plt.scatter(np.where(anomalies_ae==True), y_predict[np.where(anomalies_ae==True)], \n",
    "                    alpha=0.8, color='green', s=350, label=\"3-Sigma Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_se==True), y_predict[np.where(anomalies_se==True)], \n",
    "                    alpha=0.8, color='magenta', s=150, label = \"3-Sigma Anomalies SE\")\n",
    "        plt.legend()    \n",
    "        figName = f\"Y_predict-1-step-spikes-T_{T}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        #plt.savefig(figName, transparent=False)\n",
    "        fig.clf()\n",
    "        plt.close()\n",
    "        \n",
    "        try:\n",
    "            signature = infer_signature(X_test, y_predict)\n",
    "    \n",
    "            mlflow.tensorflow.log_model(nn_model, model_name, \n",
    "                                            signature = signature,\n",
    "                                            #input_example=X_train[0].reshape(1, -1, 1), \n",
    "                                            registered_model_name = model_name)\n",
    "        except:\n",
    "            print(f'Ray-MLFlow: Could not save model {model_name}')\n",
    "            \n",
    "        try:\n",
    "            mlflow.log_dict(three_sigma_thresholds, \"three_sigma_thresholds.json\")\n",
    "            mlflow.log_param(\"n_layer_size\", n_neurons)\n",
    "            mlflow.log_param(\"n_layers\", config['n_layers'])\n",
    "            mlflow.log_param(\"n_dense_layers\", config['n_dense_layers'])\n",
    "            mlflow.log_param(\"activation_fn\", config['activation'])\n",
    "            mlflow.log_param(\"epochs\", n_epochs)\n",
    "            mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "            mlflow.log_param(\"optimizer\", \"adam\")\n",
    "            mlflow.log_param(\"time_window\", config['T'])\n",
    "            mlflow.log_param(\"dense_dp\", config['dense_dp'])\n",
    "            mlflow.log_param(\"model_exp\", model_exp)\n",
    "            \n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "            mlflow.log_metric(\"mse\", mse)\n",
    "            mlflow.log_metric(\"mape\", mape)\n",
    "            mlflow.log_metric(\"r2_score\", r2)\n",
    "            mlflow.log_metric(\"pearson_corr_coef\", pcc)\n",
    "            \n",
    "        except:\n",
    "            exception_param_metric_dict = {}\n",
    "            log_metric_dict = {\n",
    "                'r2_score': r2,\n",
    "                'mae': mae,\n",
    "                'mape': mape,\n",
    "                'mse': mse,\n",
    "                'pcc': pcc\n",
    "            }        \n",
    "            log_param_dict = {\n",
    "                \"n_layer_size\": n_neurons,\n",
    "                \"n_layers\": config['n_layers'],\n",
    "                \"n_dense_layers\": config['n_dense_layers'],\n",
    "                \"activation_fn\": config['activation'],\n",
    "                \"epochs\": n_epochs,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"optimizer\": \"adam\",\n",
    "                \"time_window\": config['T'],\n",
    "                \"dense_dp\": config['dense_dp'],\n",
    "                \"model_exp\": model_exp            \n",
    "            }\n",
    "            exception_param_metric_dict['log_param_dict'] = log_param_dict\n",
    "            exception_param_metric_dict['log_metric_dict'] = log_metric_dict\n",
    "            mlflow.log_dict(exception_param_metric_dict, \"exception_param_metric_dict.json\")\n",
    "\n",
    "    train.report({\"mse\":mse, \"mae\":mae, \"mape\":mape, \"r2\":r2, \"mlflow_exp\":mlflow_exp_name, \"model_name\":model_name, \"T\":T, \"run_id\":run_id}) # for Ray>=2.7\n",
    "    \n",
    "    # air.session.report({\"mse\":mse, \"mae\":mae, \"mape\":mape, \"r2\":r2, \"mlflow_exp\":mlflow_exp_name, \"model_name\":model_name, \"T\":T, \"run_id\":run_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee65ce0-1017-429a-8a9a-b55770deab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(num_training_iterations, num_samples):\n",
    "    sched = AsyncHyperBandScheduler(\n",
    "        time_attr=\"training_iteration\", max_t=10, grace_period=5\n",
    "    )\n",
    "    \n",
    "    #we have a cluster of 10 worker nodes with requests 1 CPU and limits 2 CPU settings for the pod\n",
    "    resource_group = tune.PlacementGroupFactory([{'CPU': 1.0}] * 2) \n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_model, resources=resource_group),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"mse\",\n",
    "            mode=\"min\",\n",
    "            scheduler=sched,\n",
    "            num_samples=num_samples,\n",
    "            max_concurrent_trials=10,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=modelTypeName,\n",
    "            verbose = 1,\n",
    "            stop={\"training_iteration\": num_training_iterations},\n",
    "        ),\n",
    "        param_space=param_space\n",
    "    )\n",
    "    \n",
    "    results = tuner.fit()\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f19d0-f95b-47ee-b830-4cfdede4d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def run_n_step_evaluation(model_name, run_id, T, predict_ahead):\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "    mlflow.set_registry_uri(MLFLOW_URI)\n",
    "\n",
    "    model = mlflow.tensorflow.load_model(f'models:/{model_name}/1')\n",
    "\n",
    "    params = mlflow.get_run(run_id).to_dictionary()['data']['params']\n",
    "    n_neurons = params['n_layer_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    n_epochs = params['epochs']\n",
    "    model_exp = params['model_exp']\n",
    "    \n",
    "    n_step_metrics = {}\n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = prepare_dataset(dataFrame[dataColumnName], T)\n",
    "    \n",
    "    y_predict = model.predict(X_test, verbose=0)\n",
    "    y_pred_nsteps, avg_ae, avg_se = generate_nsteps_forecast(X_test, Y_test, model, predict_ahead)\n",
    "    \n",
    "    errors_ae2 = calculate_absolute_prediction_errors(Y_test, y_pred_nsteps)\n",
    "    errors_se2 = calculate_squared_prediction_errors(Y_test, y_pred_nsteps)\n",
    "\n",
    "    try:\n",
    "        r2_nStep = r2_score(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        r2_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mae_nStep = mean_absolute_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mae_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mape_nStep = mean_absolute_percentage_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mape_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mse_nStep = mean_squared_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mse_nStep = 100\n",
    "\n",
    "    try:\n",
    "        pcc_nStep = np.corrcoef(Y_test, y_pred_nsteps.flatten())[0,1]\n",
    "    except:\n",
    "        pcc_nStep = 100\n",
    "\n",
    "    crt_step = f'predict_ahead_{predict_ahead}'\n",
    "    n_step_metrics[crt_step] = {\n",
    "                                    'r2_nStep': r2_nStep,\n",
    "                                    'mae_nStep': mae_nStep,\n",
    "                                    'mape_nStep': mape_nStep,\n",
    "                                    'mse_nStep': mse_nStep,\n",
    "                                    'pcc_nStep': pcc_nStep,\n",
    "                                    'agv_ae_at_nStep': avg_ae,\n",
    "                                    'agv_se_at_nStep': avg_se\n",
    "                                   }\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id, nested=True) as run:\n",
    "        artifact_uri = run.info.artifact_uri\n",
    "        three_sigma_thresholds = mlflow.artifacts.load_dict(artifact_uri + \"/three_sigma_thresholds.json\")        \n",
    "\n",
    "        anomalies_ae2 = calculate_3sigma_anomalies(errors_ae2, \n",
    "                                                   three_sigma_thresholds['lo_3sigma_ae'], \n",
    "                                                   three_sigma_thresholds['up_3sigma_ae'])\n",
    "        anomalies_se2 = calculate_3sigma_anomalies(errors_se2, \n",
    "                                                   three_sigma_thresholds['lo_3sigma_se'], \n",
    "                                                   three_sigma_thresholds['up_3sigma_se'])\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        plt.title(\"Compare forecasts T=\" + str(T) + \" predict_ahead=\" + str(predict_ahead) + \" with predict 1\" + \n",
    "                 \" for DNN \"+ modelTypeName +\": NN=\" + str(n_neurons) + \" LR= \" + str(learning_rate) + \" epochs=\" + str(n_epochs))\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='red',linewidth=2)\n",
    "        plt.plot(y_predict,label=\"Predicted Data 1-step\", alpha=0.6, c='black', linewidth=2)\n",
    "        plt.plot(y_pred_nsteps,label=\"Predicted Data \" + str(predict_ahead) + \"-steps\", alpha=0.6, c='blue', linewidth=2)\n",
    "        plt.legend()\n",
    "        figName = f\"compare-forecasts-1_{predict_ahead}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        #plt.savefig(figName, transparent=False)\n",
    "        fig.clf()\n",
    "        plt.close()\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,15))        \n",
    "        plt.title(\"Predict Spikes T=\" + str(T) + \" with predict \" + str(predict_ahead) + \" on \" + str(model_exp) + \": NN=\" \n",
    "                  + str(n_neurons) + \" epochs=\" + str(n_epochs) + \" lr=\" + str(learning_rate))\n",
    "        plt.plot(y_pred_nsteps,label=\"Predict \" + str(predict_ahead) + \"-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='black')\n",
    "        plt.scatter(np.where(anomalies_ae2==True), y_pred_nsteps[np.where(anomalies_ae2==True)], \n",
    "                    alpha=0.8, color='green', s=350, label=\"Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_se2==True), y_pred_nsteps[np.where(anomalies_se2==True)], \n",
    "                    alpha=0.8, color='magenta', s=150, label = \"Anomalies SE\")\n",
    "        plt.legend();    \n",
    "        figName = f\"Y-predict-spikes-step-{predict_ahead}-with-T_{T}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        #plt.savefig(figName, transparent=False)\n",
    "        fig.clf()\n",
    "        plt.close()\n",
    "\n",
    "        fname = f'{predict_ahead}-step-metric.json'\n",
    "        mlflow.log_dict(n_step_metrics, fname)\n",
    "        \n",
    "    return n_step_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a2fe1-08ef-434b-aba1-e981e67dbc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def run_new_data_evaluation(model_name, run_id, T, predict_ahead, trial_fname):\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "    mlflow.set_registry_uri(MLFLOW_URI)\n",
    "\n",
    "    model = mlflow.tensorflow.load_model(f'models:/{model_name}/1')\n",
    "\n",
    "    params = mlflow.get_run(run_id).to_dictionary()['data']['params']\n",
    "    n_neurons = params['n_layer_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    n_epochs = params['epochs']\n",
    "    model_exp = params['model_exp']\n",
    "    \n",
    "    n_step_metrics = {}\n",
    "    one_step_metrics = {}\n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = prepare_dataset(dataFrame[dataColumnName], T)\n",
    "    \n",
    "    y_predict = model.predict(X_test, verbose=0)\n",
    "    errors_ae = calculate_absolute_prediction_errors(Y_test, y_predict)    \n",
    "    errors_se = calculate_squared_prediction_errors(Y_test, y_predict)\n",
    "    \n",
    "    y_pred_nsteps, avg_ae, avg_se = generate_nsteps_forecast(X_test, Y_test, model, predict_ahead)\n",
    "    errors_ae2 = calculate_absolute_prediction_errors(Y_test, y_pred_nsteps)\n",
    "    errors_se2 = calculate_squared_prediction_errors(Y_test, y_pred_nsteps)\n",
    "\n",
    "    try:\n",
    "        r2 = r2_score(Y_test, y_predict)\n",
    "    except:\n",
    "        r2 = 110\n",
    "    if np.isnan(r2):\n",
    "        r2 = 110\n",
    "\n",
    "    try:\n",
    "        mae = mean_absolute_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mae = 100\n",
    "    if np.isnan(mae):\n",
    "        mae = 100\n",
    "\n",
    "    try:\n",
    "        mape = mean_absolute_percentage_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mape = 100\n",
    "    if np.isnan(mape):\n",
    "        mape = 100\n",
    "\n",
    "    try:\n",
    "        mse = mean_squared_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mse = 100\n",
    "    if np.isnan(mse):\n",
    "        mse = 100\n",
    "    \n",
    "    try:\n",
    "        pcc = np.corrcoef(Y_test, y_predict.flatten())[0,1]\n",
    "    except:\n",
    "        pcc = 100\n",
    "    if np.isnan(pcc):\n",
    "        pcc = 100\n",
    "\n",
    "    one_step_metrics = {\n",
    "                        'r2_1Step': r2,\n",
    "                        'mae_1Step': mae,\n",
    "                        'mape_1Step': mape,\n",
    "                        'mse_1Step': mse,\n",
    "                        'pcc_1Step': pcc\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        r2_nStep = r2_score(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        r2_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mae_nStep = mean_absolute_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mae_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mape_nStep = mean_absolute_percentage_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mape_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mse_nStep = mean_squared_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mse_nStep = 100\n",
    "\n",
    "    try:\n",
    "        pcc_nStep = np.corrcoef(Y_test, y_pred_nsteps.flatten())[0,1]\n",
    "    except:\n",
    "        pcc_nStep = 100\n",
    "\n",
    "    crt_step = f'predict_ahead_{predict_ahead}'\n",
    "    n_step_metrics[crt_step] = {\n",
    "                                    'r2_nStep': r2_nStep,\n",
    "                                    'mae_nStep': mae_nStep,\n",
    "                                    'mape_nStep': mape_nStep,\n",
    "                                    'mse_nStep': mse_nStep,\n",
    "                                    'pcc_nStep': pcc_nStep,\n",
    "                                    'agv_ae_at_nStep': avg_ae,\n",
    "                                    'agv_se_at_nStep': avg_se\n",
    "                                   }\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id, nested=True) as run:\n",
    "        artifact_uri = run.info.artifact_uri\n",
    "        three_sigma_thresholds = mlflow.artifacts.load_dict(artifact_uri + \"/three_sigma_thresholds.json\")        \n",
    "\n",
    "        anomalies_ae = calculate_3sigma_anomalies(errors_ae, \n",
    "                                                   three_sigma_thresholds['lo_3sigma_ae'], \n",
    "                                                   three_sigma_thresholds['up_3sigma_ae'])\n",
    "        anomalies_se = calculate_3sigma_anomalies(errors_se, \n",
    "                                                   three_sigma_thresholds['lo_3sigma_se'], \n",
    "                                                   three_sigma_thresholds['up_3sigma_se'])\n",
    "\n",
    "        anomalies_ae2 = calculate_3sigma_anomalies(errors_ae2, \n",
    "                                                   three_sigma_thresholds['lo_3sigma_ae'], \n",
    "                                                   three_sigma_thresholds['up_3sigma_ae'])\n",
    "        anomalies_se2 = calculate_3sigma_anomalies(errors_se2, \n",
    "                                                   three_sigma_thresholds['lo_3sigma_se'], \n",
    "                                                   three_sigma_thresholds['up_3sigma_se'])\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        title = \"Compare Forecasts for T=\" + str(T) + \" with predict 1 on \"+ str(model_exp) + \" for trial \" + str(trial_fname)\n",
    "        plt.title(title)\n",
    "        plt.plot(y_predict,label=\"Predict 1-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='black')\n",
    "        plt.scatter(np.where(anomalies_ae==True), y_predict[np.where(anomalies_ae==True)], \n",
    "                    alpha=0.8, color='green', s=350, label=\"Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_se==True), y_predict[np.where(anomalies_se==True)], \n",
    "                    alpha=0.8, color='magenta', s=150, label = \"Anomalies SE\")\n",
    "        plt.legend();    \n",
    "        figName = f\"Y_predict_ahead-1-step-T_{T}-fname-{trial_fname}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        fig.clf()\n",
    "        plt.close()\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        title = \"Compare Forecasts for T=\" + str(T) + \" with predict_ahead= \"+ str(predict_ahead) + \" on model \" + str(model_exp) + \" for trial \" + str(trial_fname)\n",
    "        plt.title(title)\n",
    "        plt.plot(y_pred_nsteps,label=\"Predict n-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='black')\n",
    "        plt.scatter(np.where(anomalies_ae2==True), y_pred_nsteps[np.where(anomalies_ae2==True)], \n",
    "                    alpha=0.8, color='green', s=350, label=\"Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_se2==True), y_pred_nsteps[np.where(anomalies_se2==True)], \n",
    "                    alpha=0.8, color='magenta', s=150, label = \"Anomalies SE\")\n",
    "        plt.legend();    \n",
    "        figName = f\"Y_predict_ahead-{predict_ahead}-step-T_{T}-fname-{trial_fname}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        fig.clf()\n",
    "        plt.close()        \n",
    "\n",
    "        fname_nstep = f'{predict_ahead}-{trial_fname}-nstep-metric.json'\n",
    "        fname_1step = f'{predict_ahead}-{trial_fname}-1step-metric.json'\n",
    "        mlflow.log_dict(n_step_metrics, fname_nstep)\n",
    "        mlflow.log_dict(one_step_metrics, fname_1step)\n",
    "        \n",
    "        result = {\n",
    "            'one_step_metrics' : one_step_metrics,\n",
    "            'n_step_metrics' : n_step_metrics\n",
    "        }\n",
    "        \n",
    "    return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-CPU",
   "language": "python",
   "name": "tf-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
