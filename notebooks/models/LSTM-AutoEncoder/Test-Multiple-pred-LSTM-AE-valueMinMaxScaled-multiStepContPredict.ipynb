{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6533a91e-99ee-426b-bd3b-4ca9578f52a6",
   "metadata": {},
   "source": [
    "### Using the model from the experiment that provided the best MSE value\n",
    "Look up the results in MLFlow for the best experiment and retrieve model name and MLFlow run_id, then fill them in the appropriate cells in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18042695-fc7f-402e-aaf2-30bc7cd95bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../lib/imports.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6df785-63ce-4f84-ae45-fce19710d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTypeName = \"LSTM_AE_valueMinMaxScaled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48702a-0e74-466e-9604-8ff6cf9b1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataColumnName = 'valueMinMaxScaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48303ebc-b113-4165-b2f3-c6caa278f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../lib/utils_anomaly_detection.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc91b91-8d53-42f1-91d2-4a44eee800f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../lib/model_commons.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93067f79-f78e-4b6c-9951-c93b84d7f9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "dataFileList = !ls ../../data/rq2-valid/*msg-w-spikes*.csv\n",
    "dataLatencyFileList =  !ls ../../data/rq2-valid/*avg-latency*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17429d9-0c05-49be-aef7-8bb9a826674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0d2a3-5e74-42a1-95b7-9e6cf3601721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a4cb68-9117-44eb-9da7-479fc1afb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_run_id = '<get_the_run_id_from_MLFlow>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7ed92-3355-4647-9673-273f466fce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '<get_the_model_name_from_MLFlow>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca1451-03f0-48ec-9832-d47022dd04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_registry_uri(MLFLOW_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a7fd9-1de8-4d24-933c-975f4b22d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = mlflow.tensorflow.load_model(f'models:/{model_name}/1')\n",
    "\n",
    "model_params = mlflow.get_run(mlflow_run_id).to_dictionary()['data']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6c612-07bb-444e-a72e-4528c9a9220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39c914-48d7-4bd3-969e-745fdf6de5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = int(model_params['time_window'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4957e-ab13-4ec4-9b8e-3f8b20c3ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Set the target environment to cluster or local. Default is local\n",
    "####\n",
    "run_local = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9c9f0-f70e-4a04-9428-bf58c03550ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_local == False:\n",
    "    print(\"Running on Cluster\")\n",
    "    from codeflare_sdk import TokenAuthentication\n",
    "    from codeflare_sdk import generate_cert\n",
    "    \n",
    "    auth = TokenAuthentication(\n",
    "        token = \"<your_access_token>\", # execute ocp whoami -t on the authenticated cluster to obtain the token\n",
    "        server = \"<OCP cluster API URL>\",\n",
    "        skip_tls = True\n",
    "    )\n",
    "    auth.login()\n",
    "    \n",
    "    # Create required TLS cert and export the environment variables to enable TLS\n",
    "    generate_cert.generate_tls_cert('raycluster-complete', 'raycluster')\n",
    "    generate_cert.export_env('raycluster-complete', 'raycluster')\n",
    "    \n",
    "    ray_endpoint = 'ray://raycluster-complete-head-svc.raycluster.svc.cluster.local:10001' # ensure your ray cluster URL is correct\n",
    "    ray.shutdown()\n",
    "    ray.init(address=ray_endpoint, logging_level=logging.ERROR, log_to_driver=False)\n",
    "else:\n",
    "    ray.shutdown()\n",
    "    ray.init()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1137f25-07b1-4f58-b19f-44b71a60570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " This function uses one Tensor formatted input from the X_test dataset in order to predict ahead by a number\n",
    " of given steps. Then it readjusts by using another true value from X_test (as the nex index) before starting\n",
    " a new prediction cycle\n",
    "\"\"\"\n",
    "def generate_nsteps_forecast_ae(x_test, y_test, nn_model, enc_model, pred_ahead):\n",
    "    max_len = x_test.shape[0]\n",
    "    y_pred = []\n",
    "    last_x = x_test[0]\n",
    "    dim_shape = last_x.shape[1]\n",
    "    index = 0\n",
    "    ae_errors_at_p = []\n",
    "    se_errors_at_p = []    \n",
    "    while len(y_pred) < max_len:\n",
    "        sequence = 0\n",
    "        while sequence < pred_ahead:\n",
    "            try:\n",
    "                x_crt_input = last_x.reshape(1, -1, dim_shape)\n",
    "                p_vector = nn_model.predict(x_crt_input, verbose=0)\n",
    "                p = p_vector[0,0] # 1x1 array -> scalar\n",
    "            except:\n",
    "                print(f'Prediction error for x={x_crt_input} at sequence={sequence} for start index={index} when pred_ahead={pred_ahead}')\n",
    "                print(f'Model config was:{nn_model.get_config()}')\n",
    "                p = 0\n",
    "                \n",
    "            # update the predictions list\n",
    "            y_pred.append(p)\n",
    "\n",
    "            #prepare new_x cointaing prediction p for encoding\n",
    "            new_x = last_x[:,0] # the first column contains the original input x from X_train\n",
    "            new_x = np.roll(new_x, -1)\n",
    "            new_x[-1] = p\n",
    "            \n",
    "            try:\n",
    "                x_vector_ = np.concatenate([new_x.reshape(1, -1, D), \n",
    "                                 enc_model.predict(new_x.reshape(1, -1, D), verbose=0)], \n",
    "                                axis = -1)\n",
    "                x_ = x_vector_[0][0] # x_ is 3D we need only the last dimension as a row\n",
    "            except:\n",
    "                x_ = 0\n",
    "\n",
    "            # make the new input\n",
    "            last_x = np.roll(last_x, -1)\n",
    "            last_x[-1] = x_\n",
    "            \n",
    "            # increase index for the next run\n",
    "            sequence += 1\n",
    "\n",
    "        index += sequence\n",
    "        if index < max_len:\n",
    "            last_x = x_test[index]\n",
    "            ae_errors_at_p.append(np.absolute(p - y_test[index-1]))\n",
    "            se_errors_at_p.append(np.square(p - y_test[index-1]))\n",
    "            #print(f\"Arrived at index = {index} of {max_len} with value X={last_x}\")\n",
    "    \n",
    "    if len(y_pred) > max_len:\n",
    "        # predicted too much, cutoff the tail\n",
    "        y_pred = y_pred[0:max_len]\n",
    "        \n",
    "    y_pred_array = np.array(y_pred)\n",
    "    avg_ae = np.mean(ae_errors_at_p)\n",
    "    avg_se = np.mean(se_errors_at_p)\n",
    "    return (y_pred_array, avg_ae, avg_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f62b2d-1dfa-4976-9634-45ef9570f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def run_new_data_evaluation_ae(model_name, autoencoder_name, run_id, T, predict_ahead):\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "    mlflow.set_registry_uri(MLFLOW_URI)\n",
    "\n",
    "    model = mlflow.tensorflow.load_model(f'models:/{model_name}/1')\n",
    "    autoencoder = mlflow.tensorflow.load_model(f'models:/{autoencoder_name}/1')\n",
    "\n",
    "    params = mlflow.get_run(run_id).to_dictionary()['data']['params']\n",
    "    n_neurons = params['n_layer_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "    n_epochs = params['epochs']\n",
    "    model_exp = params['model_exp']\n",
    "    \n",
    "    n_step_metrics = {}\n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = prepare_dataset(dataFrame[dataColumnName], T)\n",
    "    \n",
    "    #autoencode input\n",
    "    X_test_ = np.concatenate([X_test, autoencoder.predict(X_test, verbose=0)], axis = -1)\n",
    "\n",
    "    n_step_metrics = {}\n",
    "    one_step_metrics = {}\n",
    "    \n",
    "    y_predict = model.predict(X_test_, verbose=0)\n",
    "    errors_ae = calculate_absolute_prediction_errors(Y_test, y_predict)    \n",
    "    errors_se = calculate_squared_prediction_errors(Y_test, y_predict)\n",
    "    \n",
    "    y_pred_nsteps, avg_ae, avg_se = generate_nsteps_forecast_ae(X_test_, Y_test, model, autoencoder, predict_ahead)    \n",
    "    errors_ae2 = calculate_absolute_prediction_errors(Y_test, y_pred_nsteps)\n",
    "    errors_se2 = calculate_squared_prediction_errors(Y_test, y_pred_nsteps)\n",
    "\n",
    "    try:\n",
    "        r2 = r2_score(Y_test, y_predict)\n",
    "    except:\n",
    "        r2 = 110\n",
    "    if np.isnan(r2):\n",
    "        r2 = 110\n",
    "\n",
    "    try:\n",
    "        mae = mean_absolute_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mae = 100\n",
    "    if np.isnan(mae):\n",
    "        mae = 100\n",
    "\n",
    "    try:\n",
    "        mape = mean_absolute_percentage_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mape = 100\n",
    "    if np.isnan(mape):\n",
    "        mape = 100\n",
    "\n",
    "    try:\n",
    "        mse = mean_squared_error(Y_test, y_predict)\n",
    "    except:\n",
    "        mse = 100\n",
    "    if np.isnan(mse):\n",
    "        mse = 100\n",
    "    \n",
    "    try:\n",
    "        pcc = np.corrcoef(Y_test, y_predict.flatten())[0,1]\n",
    "    except:\n",
    "        pcc = 100\n",
    "    if np.isnan(pcc):\n",
    "        pcc = 100\n",
    "\n",
    "    one_step_metrics = {\n",
    "                        'r2_1Step': r2,\n",
    "                        'mae_1Step': mae,\n",
    "                        'mape_1Step': mape,\n",
    "                        'mse_1Step': mse,\n",
    "                        'pcc_1Step': pcc\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        r2_nStep = r2_score(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        r2_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mae_nStep = mean_absolute_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mae_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mape_nStep = mean_absolute_percentage_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mape_nStep = 100\n",
    "\n",
    "    try:\n",
    "        mse_nStep = mean_squared_error(Y_test, y_pred_nsteps)\n",
    "    except:\n",
    "        mse_nStep = 100\n",
    "\n",
    "    try:\n",
    "        pcc_nStep = np.corrcoef(Y_test, y_pred_nsteps.flatten())[0,1]\n",
    "    except:\n",
    "        pcc_nStep = 100\n",
    "\n",
    "    crt_step = f'predict_ahead_{predict_ahead}'\n",
    "    n_step_metrics[crt_step] = {\n",
    "                                    'r2_nStep': r2_nStep,\n",
    "                                    'mae_nStep': mae_nStep,\n",
    "                                    'mape_nStep': mape_nStep,\n",
    "                                    'mse_nStep': mse_nStep,\n",
    "                                    'pcc_nStep': pcc_nStep,\n",
    "                                    'agv_ae_at_nStep': avg_ae,\n",
    "                                    'agv_se_at_nStep': avg_se\n",
    "                                   }\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id, nested=True) as run:\n",
    "        artifact_uri = run.info.artifact_uri\n",
    "        three_sigma_thresholds = mlflow.artifacts.load_dict(artifact_uri + \"/three_sigma_thresholds.json\")        \n",
    "\n",
    "        anomalies_ae = calculate_3sigma_anomalies(errors_ae, \n",
    "                                                   three_sigma_thresholds['lo_3sigma_ae'], \n",
    "                                                   three_sigma_thresholds['up_3sigma_ae'])\n",
    "        anomalies_se = calculate_3sigma_anomalies(errors_se, \n",
    "                                                   three_sigma_thresholds['lo_3sigma_se'], \n",
    "                                                   three_sigma_thresholds['up_3sigma_se'])\n",
    "\n",
    "        anomalies_ae2 = calculate_3sigma_anomalies(errors_ae2, \n",
    "                                                   three_sigma_thresholds['lo_3sigma_ae'], \n",
    "                                                   three_sigma_thresholds['up_3sigma_ae'])\n",
    "        anomalies_se2 = calculate_3sigma_anomalies(errors_se2, \n",
    "                                                   three_sigma_thresholds['lo_3sigma_se'], \n",
    "                                                   three_sigma_thresholds['up_3sigma_se'])\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        title = \"Compare Forecasts for T=\" + str(T) + \" with predict 1 on \"+ str(model_exp) + \" for trial \" + str(trial_fname)\n",
    "        plt.title(title)\n",
    "        plt.plot(y_predict,label=\"Predict 1-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='black')\n",
    "        plt.scatter(np.where(anomalies_ae==True), y_predict[np.where(anomalies_ae==True)], \n",
    "                    alpha=0.8, color='green', s=350, label=\"Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_se==True), y_predict[np.where(anomalies_se==True)], \n",
    "                    alpha=0.8, color='magenta', s=150, label = \"Anomalies SE\")\n",
    "        plt.legend();    \n",
    "        figName = f\"Y_predict_ahead-1-step-T_{T}-fname-{trial_fname}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        fig.clf()\n",
    "        plt.close()\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        title = \"Compare Forecasts for T=\" + str(T) + \" with predict_ahead= \"+ str(predict_ahead) + \" on model \" + str(model_exp) + \" for trial \" + str(trial_fname)\n",
    "        plt.title(title)\n",
    "        plt.plot(y_pred_nsteps,label=\"Predict n-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "        plt.plot(Y_test,label=\"Original Data\", alpha=0.6, c='black')\n",
    "        plt.scatter(np.where(anomalies_ae2==True), y_pred_nsteps[np.where(anomalies_ae2==True)], \n",
    "                    alpha=0.8, color='green', s=350, label=\"Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_se2==True), y_pred_nsteps[np.where(anomalies_se2==True)], \n",
    "                    alpha=0.8, color='magenta', s=150, label = \"Anomalies SE\")\n",
    "        plt.legend();    \n",
    "        figName = f\"Y_predict_ahead-{predict_ahead}-step-T_{T}-fname-{trial_fname}.png\"\n",
    "        mlflow.log_figure(fig, figName)\n",
    "        fig.clf()\n",
    "        plt.close()        \n",
    "\n",
    "        fname_nstep = f'{predict_ahead}-{trial_fname}-nstep-metric.json'\n",
    "        fname_1step = f'{predict_ahead}-{trial_fname}-1step-metric.json'\n",
    "        mlflow.log_dict(n_step_metrics, fname_nstep)\n",
    "        mlflow.log_dict(one_step_metrics, fname_1step)\n",
    "        \n",
    "        result = {\n",
    "            'one_step_metrics' : one_step_metrics,\n",
    "            'n_step_metrics' : n_step_metrics\n",
    "        }\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38f8cc-ee67-4ab2-b395-fe2659e04f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_trials = {}\n",
    "for filePos in range(len(dataFileList)):\n",
    "    \n",
    "    data = pd.read_csv(dataFileList[filePos], index_col='EventDateTime', parse_dates=['EventDateTime'])\n",
    "    dataLatency = pd.read_csv(dataLatencyFileList[filePos], index_col='EventDateTime', parse_dates=['EventDateTime'])\n",
    "    print(f'Processing files at position {filePos} in list')\n",
    "    %run '../lib/prepareDataSet.ipynb'\n",
    "\n",
    "    trial_fname = os.path.basename(dataFileList[filePos])\n",
    "    results_predict_ahead = {}\n",
    "    for predict_ahead in [5, 10, 15, 30, 45, 60, 90, 120]:\n",
    "        res = run_new_data_evaluation_ae.remote(model_name, mlflow_run_id, T, predict_ahead, trial_fname)\n",
    "        tag = f'predict_ahead_{predict_ahead}-trial_{trial_fname}'\n",
    "        results_predict_ahead[tag] = res\n",
    "        \n",
    "    results_trials[trial_fname] = results_predict_ahead    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3784c92-cc64-4e67-8fe5-9c057795063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2001e0-b7f3-4ec5-a71f-df66a188e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trials = {}\n",
    "for trial in results_trials.keys():\n",
    "    data_trial = {}\n",
    "    for item in results_trials[trial].keys():\n",
    "        try:\n",
    "            res = ray.get(results_trials[trial][item])\n",
    "        except:\n",
    "            print(f'Error getting results for key:{item}')\n",
    "            res = None\n",
    "        data_trial[item] = res\n",
    "        \n",
    "    data_trials[trial] = data_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8d6f4-44c3-4b06-86f3-56d3a99f9ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0d1ed-e2c9-4a45-85e0-c9892954ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b3702c-2888-4ea4-8ae9-63b383fc0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_result():\n",
    "    min_mse = 1000\n",
    "    tag = ''\n",
    "    result = {}\n",
    "    for trial in data_trials.keys():\n",
    "        crt_trial = data_trials[trial]\n",
    "        for predict_ahead in crt_trial.keys():\n",
    "            crt_one_step = crt_trial[predict_ahead]['one_step_metrics']\n",
    "            if crt_one_step['mse_1Step'] < min_mse:\n",
    "                min_mse = crt_one_step['mse_1Step']\n",
    "                tag = str(predict_ahead) + '-' + str(trial)\n",
    "                result = crt_trial[predict_ahead]\n",
    "\n",
    "    return result, tag\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1602176-836d-4e82-83cb-e93b473b3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7a062-239d-4ff2-bdac-9f4d217aab2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-CPU",
   "language": "python",
   "name": "tf-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
