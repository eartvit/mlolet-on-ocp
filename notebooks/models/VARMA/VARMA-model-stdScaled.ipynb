{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83134b89-3995-4737-b1b1-c1811888913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataColumnName = 'valueStdScaled'\n",
    "model_exp = 'VARMA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232b298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'T' not in globals():\n",
    "    T = 15\n",
    "if 'predict_ahead' not in globals():\n",
    "    predict_ahead = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732396ed-a61e-4dac-b1f0-8946744b55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65657b3-8f2e-489d-8576-f5525efa779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "data = pd.read_csv('../../data/rq_1-3_train_test/2024-01-15_10-51-45__2024-01-15_14-26-45_load-gen-msg-w-spikes-10s-rate.csv', \n",
    "                   index_col=['EventDateTime'], parse_dates=['EventDateTime'])\n",
    "dataLatency = pd.read_csv('../../data/rq_1-3_train_test/2024-01-15_10-51-45__2024-01-15_14-26-45_load-gen-avg-latency-10s-rate.csv', \n",
    "                          index_col='EventDateTime', parse_dates=['EventDateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ae1bc-8311-4159-923f-facd25f0c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc9c1b-3229-4a34-bd77-3c5fa3c127ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run '../lib/prepareDataSet.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661c817-1c34-4116-949d-7c66f786cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../lib/utils_anomaly_detection.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbdec01-556e-4bf1-8192-044ee1446821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e0330-7271-4fd0-a29a-3409a62a1b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1e712-5461-4145-8cb6-b11b4bbc1763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from statsmodels.graphics.tsaplots import plot_acf, plot_pacf, plot_predict\n",
    "#from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from statsmodels.tsa.api import VAR\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8549185-076c-4793-ac1e-593754644d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dataFrame_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f284028-25e5-46cb-8f0a-8e66f05a69e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test['TimeLatencyStdScaled'] = dataFrameLatency_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c86ad1-7662-4d72-8a18-603a66bb91e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ef8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e19855f-acbd-4371-91d2-eb1b5ad58e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['valueStdScaled', 'TimeLatencyStdScaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae1ece-2683-43b6-866b-a13cccf01f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = dataFrame_train.to_frame()\n",
    "X_train['TimeLatencyStdScaled'] = dataFrameLatency_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639cc24a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2bfc42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VAR requires 2 time series. We have both response time and throughput available\n",
    "# We also set the maxlags with the same value we use for the neural nets, namely T. \n",
    "# This means it will use the previous T values to predicts the next one.\n",
    "# This is useful as we always have the real value (the T+1th value) so we can compare it with the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbef3e8-8fc0-4a11-b534-23715bc342eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_VAR = VAR(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b8dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lag_order_results = model_VAR.select_order(maxlags=T)\n",
    "lag_order_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38517932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lag_order_results.selected_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b5645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_VAR = model_VAR.fit(maxlags=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc3b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lag_order = results_VAR.k_ar\n",
    "lag_order # ensuring the maxlags is unchanged after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379117b8-c311-48ea-8550-0a17c179cc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function generates the forecasts values for the test dataset, one step at a time\n",
    "def generate_forecasts(x_test, model_VAR, T):\n",
    "    forecasts_VAR = []\n",
    "    for i in range(x_test.shape[0]-T+1): # we can't go past T and we start predicting the T+1 value\n",
    "        prior = x_test[i:i+T][['valueStdScaled','TimeLatencyStdScaled']].to_numpy()\n",
    "        fcast_VAR = model_VAR.forecast(prior, 1)\n",
    "        forecasts_VAR.append(fcast_VAR)\n",
    "        i += 1\n",
    "    \n",
    "    return forecasts_VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8394b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function generates the forecasts values for the test dataset\n",
    "# It predicts predict_ahead steps before getting a new ground truth value and predicts the next batch\n",
    "def generate_nsteps_forecasts(x_test, model_VAR, T, predict_ahead):    \n",
    "    y_predict = []\n",
    "    index = 0\n",
    "    while (index < x_test.shape[0]-T+1):\n",
    "    #while len(y_predict) < x_test.shape[0]-T:\n",
    "        #print(f'Selecting input from index {index} to {index+T}')\n",
    "        last_x = x_test[index: index+T]\n",
    "        p = model_VAR.forecast(last_x, predict_ahead)\n",
    "        y_predict.append(p)\n",
    "        index += predict_ahead\n",
    "\n",
    "    y_pred_conc = y_predict[0]\n",
    "    i=1\n",
    "    while i < len(y_predict):\n",
    "        y_pred_conc = np.concatenate((y_pred_conc, y_predict[i]), axis=0)\n",
    "        i+=1\n",
    "\n",
    "    return y_pred_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5baef-7a00-4e56-9306-d7f500e05df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valueStdScaled = []\n",
    "Y_train_valueStdScaled = []\n",
    "\n",
    "(X_train_valueStdScaled, Y_train_valueStdScaled) = formatData(X_train_valueStdScaled, Y_train_valueStdScaled, \n",
    "                                                          X_train, T, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af2a6f-a392-470b-b978-a7cc2a17aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valueStdScaled.shape, Y_train_valueStdScaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c2c48-f64e-4e0c-8382-62eb3621e749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_valueStdScaled = []\n",
    "Y_test_valueStdScaled = []\n",
    "\n",
    "(X_test_valueStdScaled, Y_test_valueStdScaled) = formatData(X_test_valueStdScaled, Y_test_valueStdScaled, \n",
    "                                                          X_test, T, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7f554-6398-4b0d-9848-b2bbcbc6d246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_test_valueStdScaled.shape, X_test_valueStdScaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4fbd74-7605-47b6-8efe-e173868b72fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_valueStdScaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265f04f-3077-4b95-aac3-849b7db4dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = generate_forecasts(X_train, results_VAR, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e7bb9-0756-4a96-a2f3-13dc05310f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a317b63-2ce2-46f3-8ce9-b4f8387f6eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = y_pred_train[0:X_train_valueStdScaled.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4c045-c856-4954-b9ea-34bd2cd53732",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b9e37-fc3e-4f46-9da8-c0d28918aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = np.array(y_pred_train).reshape(-1,2)\n",
    "YY_train_pred = pd.DataFrame(Y_train_pred, columns=['valueStdScaled', 'TimeLatencyStdScaled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9621bd-8220-4615-9298-cbbac186e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "YY_train_pred.shape, Y_train_valueStdScaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef15da-d114-4083-a503-9d9e45126875",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = generate_forecasts(X_test, results_VAR, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b0b393",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_n_steps = generate_nsteps_forecasts(X_test.to_numpy(), results_VAR, T, predict_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7212e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(y_pred), len(y_pred_n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23172945-5e70-4cfe-8d49-02efc9210aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred[0:X_test_valueStdScaled.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5626c9-031d-4e9f-b732-db419ed8c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_n_steps = y_pred_n_steps[0:X_test_valueStdScaled.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd88785d-1a26-4490-a064-30a028a1e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred1step = np.array(y_pred).reshape(-1,2)\n",
    "Y_test_pred_1_step = pd.DataFrame(Y_test_pred1step, columns=['valueStdScaled', 'TimeLatencyStdScaled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b4cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_test_prednsteps = np.array(y_pred_n_steps).reshape(-1,2)\n",
    "Y_test_pred_n_steps = pd.DataFrame(Y_test_prednsteps, columns=['valueStdScaled', 'TimeLatencyStdScaled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c9863-0bce-43b5-a9bb-2319a64cb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred_n_steps.shape, Y_test_pred_1_step.shape, Y_test_valueStdScaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d8225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def expand_dataframe_with_nsteps(expand_df, steps):\n",
    "#    for i in range(steps):\n",
    "#        new_row = []\n",
    "#        new_row.insert(0,{'valueStdScaled': expand_df['valueStdScaled'][0], \n",
    "#                          'TimeLatencyStdScaled': expand_df['TimeLatencyStdScaled'][0]})\n",
    "#        nr = pd.DataFrame(new_row)\n",
    "#        expand_df = pd.concat([nr, expand_df], ignore_index=True)  \n",
    "#    \n",
    "#    return expand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d034c52-d638-41a8-a716-38bebd6ce48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_arr = np.array(Y_train_valueStdScaled).reshape(-1,2)\n",
    "Y_train_frame = pd.DataFrame(Y_train_arr, columns=['valueStdScaled', 'TimeLatencyStdScaled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aaca6b-9aa1-4da0-ba80-0e883d594d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_arr = np.array(Y_test_valueStdScaled).reshape(-1,2)\n",
    "Y_test_frame = pd.DataFrame(Y_test_arr, columns=['valueStdScaled', 'TimeLatencyStdScaled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184e2a3-f8b8-4020-a445-e762b58fdcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_ae_train_value = calculate_absolute_prediction_errors(Y_train_frame['valueStdScaled'].to_numpy(), YY_train_pred['valueStdScaled'].to_numpy())\n",
    "lo_3sigma_ae_value, up_3sigma_ae_value = calculate_3sigma_threshold(errors_ae_train_value)\n",
    "anomalies_ae_train_value = calculate_3sigma_anomalies(errors_ae_train_value, lo_3sigma_ae_value, up_3sigma_ae_value)\n",
    "\n",
    "errors_se_train_value = calculate_squared_prediction_errors(Y_train_frame['valueStdScaled'].to_numpy(), YY_train_pred['valueStdScaled'].to_numpy())\n",
    "lo_3sigma_se_value, up_3sigma_se_value = calculate_3sigma_threshold(errors_se_train_value)\n",
    "anomalies_se_train_value = calculate_3sigma_anomalies(errors_se_train_value, lo_3sigma_se_value, up_3sigma_se_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0842f64-17ae-440d-b31a-e4aee40d6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_ae_train_time = calculate_absolute_prediction_errors(Y_train_frame['TimeLatencyStdScaled'].to_numpy(), YY_train_pred['TimeLatencyStdScaled'].to_numpy())\n",
    "lo_3sigma_ae_time, up_3sigma_ae_time = calculate_3sigma_threshold(errors_ae_train_time)\n",
    "anomalies_ae_train_time = calculate_3sigma_anomalies(errors_ae_train_time, lo_3sigma_ae_time, up_3sigma_ae_time)\n",
    "\n",
    "errors_se_train_time = calculate_squared_prediction_errors(Y_train_frame['TimeLatencyStdScaled'].to_numpy(), YY_train_pred['TimeLatencyStdScaled'].to_numpy())\n",
    "lo_3sigma_se_time, up_3sigma_se_time = calculate_3sigma_threshold(errors_se_train_time)\n",
    "anomalies_se_train_time = calculate_3sigma_anomalies(errors_se_train_time, lo_3sigma_se_time, up_3sigma_se_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e18e3-3a5d-4144-bc7c-625c97db93d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_ae_test_value = calculate_absolute_prediction_errors(Y_test_frame['valueStdScaled'].to_numpy(), Y_test_pred_1_step['valueStdScaled'].to_numpy())\n",
    "anomalies_ae_test_value = calculate_3sigma_anomalies(errors_ae_test_value, lo_3sigma_ae_value, up_3sigma_ae_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32e0b9-79a4-4e02-8755-3a9eabc250e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_se_test_value = calculate_squared_prediction_errors(Y_test_frame['valueStdScaled'].to_numpy(), Y_test_pred_1_step['valueStdScaled'].to_numpy())\n",
    "anomalies_se_test_value = calculate_3sigma_anomalies(errors_se_test_value, lo_3sigma_se_value, up_3sigma_se_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc0e518-88d7-489b-b678-e884b37e6aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_ae_test_time = calculate_absolute_prediction_errors(Y_test_frame['TimeLatencyStdScaled'].to_numpy(), Y_test_pred_1_step['TimeLatencyStdScaled'].to_numpy())\n",
    "anomalies_ae_test_time = calculate_3sigma_anomalies(errors_ae_test_time, lo_3sigma_ae_time, up_3sigma_ae_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c924ee0-39a8-4e6e-a3bf-e3c79f4c41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_se_test_time = calculate_squared_prediction_errors(Y_test_frame['TimeLatencyStdScaled'].to_numpy(), Y_test_pred_1_step['TimeLatencyStdScaled'].to_numpy())\n",
    "anomalies_se_test_time = calculate_3sigma_anomalies(errors_se_test_time, lo_3sigma_se_time, up_3sigma_se_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e35547-297c-4ac1-a878-f8e3f7e552ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "plt.title(\"Predict Spikes 1-step Y_test Value\")\n",
    "plt.plot(Y_test_frame['valueStdScaled'].to_numpy(),label=\"Original Data\", alpha=0.6, c='gray')\n",
    "plt.plot(Y_test_pred_1_step['valueStdScaled'].to_numpy(),label=\"Predict 1 step\", alpha=0.6, c='red')\n",
    "plt.scatter(np.where(anomalies_ae_test_value==True)[0], Y_test_frame['valueStdScaled'].to_numpy()[np.where(anomalies_ae_test_value==1)], \n",
    "            alpha=0.8, color='green', s=300, label=\"3-Sigma Anomalies AE\")\n",
    "plt.scatter(np.where(anomalies_se_test_value==True)[0], Y_test_frame['valueStdScaled'].to_numpy()[np.where(anomalies_se_test_value==1)], \n",
    "            alpha=0.8, color='magenta', s=150, label=\"3-Sigma Anomalies SE\")\n",
    "plt.legend()\n",
    "figName = f\"Y_test_value_1-step_spikes-T_{T}-StdScaled.png\"\n",
    "#mlflow.log_figure(fig, figName)\n",
    "plt.savefig(figName, transparent=False)\n",
    "#fig.clf()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb0dc5-b295-4a52-a13a-2539eb7dddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "plt.title(\"Predict Spikes 1-step Y_test TimeLatency\")\n",
    "plt.plot(Y_test_frame['TimeLatencyStdScaled'].to_numpy(),label=\"Original Data\", alpha=0.6, c='gray')\n",
    "plt.plot(Y_test_pred_1_step['TimeLatencyStdScaled'].to_numpy(),label=\"Predict 1 step\", alpha=0.6, c='red')\n",
    "plt.scatter(np.where(anomalies_ae_test_time==True)[0], Y_test_frame['TimeLatencyStdScaled'].to_numpy()[np.where(anomalies_ae_test_time==1)], \n",
    "            alpha=0.8, color='green', s=300, label=\"3-Sigma Anomalies AE\")\n",
    "plt.scatter(np.where(anomalies_se_test_time==True)[0], Y_test_frame['TimeLatencyStdScaled'].to_numpy()[np.where(anomalies_se_test_time==1)], \n",
    "            alpha=0.8, color='magenta', s=150, label=\"3-Sigma Anomalies SE\")\n",
    "plt.legend()\n",
    "figName = f\"Y_test_time_1-step_spikes-T_{T}-StdScaled.png\"\n",
    "#mlflow.log_figure(fig, figName)\n",
    "plt.savefig(figName, transparent=False)\n",
    "#fig.clf()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d0d2c-8cd2-46fc-a3d9-3d41c9afec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_ae_test_value_nstep = calculate_absolute_prediction_errors(Y_test_frame['valueStdScaled'].to_numpy(), Y_test_pred_n_steps['valueStdScaled'].to_numpy())\n",
    "anomalies_ae_test_value_nstep = calculate_3sigma_anomalies(errors_ae_test_value_nstep, lo_3sigma_ae_value, up_3sigma_ae_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83cb87-0ea4-433e-996d-0d2a1385337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_se_test_value_nstep = calculate_squared_prediction_errors(Y_test_frame['valueStdScaled'].to_numpy(), Y_test_pred_n_steps['valueStdScaled'].to_numpy())\n",
    "anomalies_se_test_value_n_step = calculate_3sigma_anomalies(errors_se_test_value_nstep, lo_3sigma_se_value, up_3sigma_se_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab2c321-a1c7-4ff1-8027-d14e125f8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_ae_test_time_nstep = calculate_absolute_prediction_errors(Y_test_frame['TimeLatencyStdScaled'].to_numpy(), Y_test_pred_n_steps['TimeLatencyStdScaled'].to_numpy())\n",
    "anomalies_ae_test_time_nstep = calculate_3sigma_anomalies(errors_ae_test_time_nstep, lo_3sigma_ae_time, up_3sigma_ae_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5c68a-63b4-4764-83d5-63d849dc81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_se_test_time_nstep = calculate_squared_prediction_errors(Y_test_frame['TimeLatencyStdScaled'].to_numpy(), Y_test_pred_n_steps['TimeLatencyStdScaled'].to_numpy())\n",
    "anomalies_se_test_time_nstep = calculate_3sigma_anomalies(errors_se_test_time_nstep, lo_3sigma_se_time, up_3sigma_se_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a391e77-4ccc-468a-a8e9-3fda383b4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "plt.title(f\"Predict Spikes {predict_ahead}-steps Y_test Value\")\n",
    "plt.plot(Y_test_frame['valueStdScaled'].to_numpy(),label=\"Original Data\", alpha=0.6, c='gray')\n",
    "plt.plot(Y_test_pred_n_steps['valueStdScaled'].to_numpy(),label=\"Predict n_step\", alpha=0.6, c='red')\n",
    "plt.scatter(np.where(anomalies_ae_test_value_nstep==True)[0], Y_test_frame['valueStdScaled'].to_numpy()[np.where(anomalies_ae_test_value_nstep==1)], \n",
    "            alpha=0.8, color='green', s=300, label=\"3-Sigma Anomalies AE\")\n",
    "plt.scatter(np.where(anomalies_se_test_value_n_step==True)[0], Y_test_frame['valueStdScaled'].to_numpy()[np.where(anomalies_se_test_value_n_step==1)], \n",
    "            alpha=0.8, color='magenta', s=150, label=\"3-Sigma Anomalies SE\")\n",
    "plt.legend()\n",
    "figName = f\"Y_test_value_{predict_ahead}-step_spikes-T_{T}-StdScaled.png\"\n",
    "#mlflow.log_figure(fig, figName)\n",
    "plt.savefig(figName, transparent=False)\n",
    "#fig.clf()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156883b-19ae-496d-aa98-290a267f4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "plt.title(f\"Predict Spikes {predict_ahead}-steps Y_test TimeLatency\")\n",
    "plt.plot(Y_test_frame['TimeLatencyStdScaled'].to_numpy(),label=\"Original Data\", alpha=0.6, c='gray')\n",
    "plt.plot(Y_test_pred_n_steps['TimeLatencyStdScaled'].to_numpy(),label=\"Predict n_step\", alpha=0.6, c='red')\n",
    "plt.scatter(np.where(anomalies_ae_test_time_nstep==True)[0], Y_test_frame['TimeLatencyStdScaled'].to_numpy()[np.where(anomalies_ae_test_time_nstep==1)], \n",
    "            alpha=0.8, color='green', s=300, label=\"3-Sigma Anomalies AE\")\n",
    "plt.scatter(np.where(anomalies_se_test_time_nstep==True)[0], Y_test_frame['TimeLatencyStdScaled'].to_numpy()[np.where(anomalies_se_test_time_nstep==1)], \n",
    "            alpha=0.8, color='magenta', s=150, label=\"3-Sigma Anomalies SE\")\n",
    "plt.legend()\n",
    "figName = f\"Y_test_time_{predict_ahead}-step_spikes-T_{T}-StdScaled.png\"\n",
    "#mlflow.log_figure(fig, figName)\n",
    "plt.savefig(figName, transparent=False)\n",
    "#fig.clf()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248ac22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aic = calculate_aic(len(Y_test_frame['TimeLatencyStdScaled']), \n",
    "                    mean_squared_error(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_1_step['TimeLatencyStdScaled']),\n",
    "                    2\n",
    "                   )\n",
    "\n",
    "print(f\"Calculating scores for TimeLatencyStdScaled with forecast T={T}, predict_ahead=1\\n\"\n",
    "      f\" R2: {r2_score(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_1_step['TimeLatencyStdScaled'])} \\n\"\n",
    "      f\"MAE: {mean_absolute_error(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_1_step['TimeLatencyStdScaled'])}\\n\"\n",
    "      f\"MAPE: {mean_absolute_percentage_error(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_1_step['TimeLatencyStdScaled'])}\\n\"\n",
    "      f\"MSE: {mean_squared_error(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_1_step['TimeLatencyStdScaled'])}\\n\"\n",
    "      f\"Pearson correlation: {np.corrcoef(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_1_step['TimeLatencyStdScaled'])[0,1]}\\n\"\n",
    "      f\"AIC: {aic}\\n\"      \n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819dcb64-3f98-4b9c-8a76-48f55e7f9d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aic = calculate_aic(len(Y_test_frame['valueStdScaled']), \n",
    "                    mean_squared_error(Y_test_frame['valueStdScaled'], Y_test_pred_n_steps['valueStdScaled']),\n",
    "                    2\n",
    "                   )\n",
    "\n",
    "print(f\"Calculating scores for valueStdScaled with forecast T={T}, predict_ahead=1\\n\"\n",
    "      f\" R2: {r2_score(Y_test_frame['valueStdScaled'], Y_test_pred_1_step['valueStdScaled'])} \\n\"\n",
    "      f\"MAE: {mean_absolute_error(Y_test_frame['valueStdScaled'], Y_test_pred_1_step['valueStdScaled'])}\\n\"\n",
    "      f\"MAPE: {mean_absolute_percentage_error(Y_test_frame['valueStdScaled'], Y_test_pred_1_step['valueStdScaled'])}\\n\"\n",
    "      f\"MSE: {mean_squared_error(Y_test_frame['valueStdScaled'], Y_test_pred_1_step['valueStdScaled'])}\\n\"\n",
    "      f\"Pearson correlation: {np.corrcoef(Y_test_frame['valueStdScaled'], Y_test_pred_1_step['valueStdScaled'])[0,1]}\\n\"\n",
    "      f\"AIC: {aic}\\n\"      \n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70476749-29a3-4379-a80d-162a03ffc445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aic = calculate_aic(len(Y_test_frame['TimeLatencyStdScaled']), \n",
    "                    mean_squared_error(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_n_steps['TimeLatencyStdScaled']),\n",
    "                    2\n",
    "                   )\n",
    "\n",
    "print(f\"Calculating scores for TimeLatencyStdScaled with forecast T={T}, predict_ahead={predict_ahead}\\n\"\n",
    "      f\" R2: {r2_score(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_n_steps['TimeLatencyStdScaled'])} \\n\"\n",
    "      f\"MAE: {mean_absolute_error(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_n_steps['TimeLatencyStdScaled'])}\\n\"\n",
    "      f\"MAPE: {mean_absolute_percentage_error(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_n_steps['TimeLatencyStdScaled'])}\\n\"\n",
    "      f\"MSE: {mean_squared_error(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_n_steps['TimeLatencyStdScaled'])}\\n\"\n",
    "      f\"Pearson correlation: {np.corrcoef(Y_test_frame['TimeLatencyStdScaled'], Y_test_pred_n_steps['TimeLatencyStdScaled'])[0,1]}\\n\"\n",
    "      f\"AIC: {aic}\\n\"      \n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b0829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aic = calculate_aic(len(Y_test_frame['valueStdScaled']), \n",
    "                    mean_squared_error(Y_test_frame['valueStdScaled'], Y_test_pred_n_steps['valueStdScaled']),\n",
    "                    2\n",
    "                   )\n",
    "print(f\"Calculating scores for valueStdScaled with forecast T={T}, predict_ahead={predict_ahead}\\n\"\n",
    "      f\" R2: {r2_score(Y_test_frame['valueStdScaled'], Y_test_pred_n_steps['valueStdScaled'])} \\n\"\n",
    "      f\"MAE: {mean_absolute_error(Y_test_frame['valueStdScaled'], Y_test_pred_n_steps['valueStdScaled'])}\\n\"\n",
    "      f\"MAPE: {mean_absolute_percentage_error(Y_test_frame['valueStdScaled'], Y_test_pred_n_steps['valueStdScaled'])}\\n\"\n",
    "      f\"MSE: {mean_squared_error(Y_test_frame['valueStdScaled'], Y_test_pred_n_steps['valueStdScaled'])}\\n\"\n",
    "      f\"Pearson correlation: {np.corrcoef(Y_test_frame['valueStdScaled'], Y_test_pred_n_steps['valueStdScaled'])[0,1]}\\n\"\n",
    "      f\"AIC: {aic}\\n\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f2203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_VAR.save('results_VAR_stdScaled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef631c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "dataFileList = !ls ../../data/rq2-valid/*msg-w-spikes*.csv\n",
    "dataLatencyFileList =  !ls ../../data/rq2-valid/*avg-latency*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fce360-5f30-492b-90dc-23abd4abec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Update the below on the latest from above calculations on 3-Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for filePos in range(len(dataFileList)):\n",
    "    \n",
    "    data = pd.read_csv(dataFileList[filePos], index_col='EventDateTime', parse_dates=['EventDateTime'])\n",
    "    dataLatency = pd.read_csv(dataLatencyFileList[filePos], index_col='EventDateTime', parse_dates=['EventDateTime'])\n",
    "    print(f'Processing files at position {filePos} in list')\n",
    "    %run '../lib/prepareDataSet.ipynb'\n",
    "    #cols = ['valueStdScaled', 'TimeLatencyStdScaled']\n",
    "    trial_fname = os.path.basename(dataFileList[filePos])\n",
    "\n",
    "    X_test = dataFrame_test.to_frame()\n",
    "    X_test['TimeLatencyStdScaled'] = dataFrameLatency_test\n",
    "\n",
    "    y_pred = generate_forecasts(X_test, results_VAR, T)\n",
    "    X = np.array(y_pred).reshape(-1,2)\n",
    "    XX = pd.DataFrame(X, columns=['valueStdScaled', 'TimeLatencyStdScaled'])\n",
    "    XX_new = None\n",
    "    shape_dif = X_test.shape[0] - XX.shape[0] \n",
    "    if shape_dif > 0:\n",
    "        XX_new = expand_dataframe_with_nsteps(XX, shape_dif)\n",
    "    elif shape_dif < 0:\n",
    "        XX_new = XX2[0:X_test.shape[0]]\n",
    "    else:\n",
    "        XX_new = XX.copy()\n",
    "\n",
    "    XX = XX_new.copy()\n",
    "    XX.set_index(X_test.index, inplace=True)\n",
    "    # These are the predictions one step at a time always looking at the ground truth\n",
    "    X_test['valueStdScaledVarForecast'] = XX['valueStdScaled']\n",
    "    X_test['TimeLatencyStdScaledVarForecast'] = XX['TimeLatencyStdScaled']    \n",
    "\n",
    "    errors_ae = calculate_absolute_prediction_errors(X_test['valueStdScaled'].to_numpy(), X_test['valueStdScaledVarForecast'].to_numpy())\n",
    "    anomalies_ae = calculate_3sigma_anomalies(errors_ae)\n",
    "    errors_se = calculate_squared_prediction_errors(X_test['valueStdScaled'].to_numpy(), X_test['valueStdScaledVarForecast'].to_numpy())\n",
    "    anomalies_se = calculate_3sigma_anomalies(errors_se)\n",
    "    \n",
    "    anomalies_3sigma_Y_test = calculate_3sigma_anomalies(X_test['valueStdScaled'].to_numpy())\n",
    "    anomalies_3sigma_y_predict = calculate_3sigma_anomalies(X_test['valueStdScaledVarForecast'].to_numpy())\n",
    "    \n",
    "    anomalies_Y_test, z_scores_Y_test = calculate_zscore_anomalies(X_test['valueStdScaled'].to_numpy())\n",
    "    anomalies_y_predict, z_scores_y_predict = calculate_zscore_anomalies(X_test['valueStdScaledVarForecast'].to_numpy())\n",
    "    anomalies_errors_ae, z_scores_errors_ae = calculate_zscore_anomalies(errors_ae)\n",
    "    anomalies_errors_se, z_scores_errors_se = calculate_zscore_anomalies(errors_se)\n",
    "    \n",
    "    anomalies_Y_test_mod, z_scores_Y_test_mod = calculate_modified_zscore_anomalies(X_test['valueStdScaled'].to_numpy())\n",
    "    anomalies_y_predict_mod, z_scores_y_predict_mod = calculate_modified_zscore_anomalies(X_test['valueStdScaledVarForecast'].to_numpy())\n",
    "    anomalies_errors_ae_mod, z_scores_errors_ae_mod = calculate_modified_zscore_anomalies(errors_ae)\n",
    "    anomalies_errors_se_mod, z_scores_errors_se_mod = calculate_modified_zscore_anomalies(errors_se)\n",
    "\n",
    "    aic = calculate_aic(len(X_test['TimeLatencyStdScaled']), \n",
    "                        mean_squared_error(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast']),\n",
    "                        2)\n",
    "    \n",
    "    one_step_timeLatency = {\n",
    "        'r2_score': r2_score(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast']),\n",
    "        'mae': mean_absolute_error(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast']),\n",
    "        'mape': mean_absolute_percentage_error(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast']),\n",
    "        'mse': mean_squared_error(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast']),\n",
    "        'pcc': np.corrcoef(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast'])[0,1],\n",
    "        'aic': aic\n",
    "    }\n",
    "\n",
    "    aic = calculate_aic(len(X_test['valueStdScaled']), \n",
    "                        mean_squared_error(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast']),\n",
    "                        2)\n",
    "    \n",
    "    one_step_throughput = {\n",
    "        'r2_score': r2_score(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast']),\n",
    "        'mae': mean_absolute_error(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast']),\n",
    "        'mape': mean_absolute_percentage_error(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast']),\n",
    "        'mse': mean_squared_error(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast']),\n",
    "        'pcc': np.corrcoef(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast'])[0,1],\n",
    "        'aic': aic\n",
    "    }\n",
    "\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    plt.title(\"Predict Anomalies T=\" + str(T) + \" with predict 1 on \"+ str(model_exp))\n",
    "    plt.plot(X_test['valueStdScaledVarForecast'].to_numpy(),label=\"Predict 1-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "    plt.plot(X_test['valueStdScaled'].to_numpy(),label=\"Original Data\", alpha=0.6, c='black')\n",
    "    plt.scatter(np.where(anomalies_ae==True), X_test['valueStdScaledVarForecast'].to_numpy()[np.where(anomalies_ae==True)], \n",
    "                alpha=0.8, color='green', s=350, label=\"3-Sigma Anomalies AE\")\n",
    "    plt.scatter(np.where(anomalies_se==True), X_test['valueStdScaledVarForecast'].to_numpy()[np.where(anomalies_se==True)], \n",
    "                alpha=0.8, color='magenta', s=300, label = \"3-Sigma Anomalies SE\")\n",
    "    plt.scatter(np.where(anomalies_errors_ae==True), X_test['valueStdScaledVarForecast'].to_numpy()[np.where(anomalies_errors_ae==True)], \n",
    "                alpha=0.8, color='blue', s=250, label = \"Z-score Anomalies AE\")\n",
    "    plt.scatter(np.where(anomalies_errors_se==True), X_test['valueStdScaledVarForecast'].to_numpy()[np.where(anomalies_errors_se==True)], \n",
    "                alpha=0.8, color='cyan', s=200, label = \"Z-score Anomalies SE\")\n",
    "    plt.scatter(np.where(anomalies_errors_ae_mod==True), X_test['valueStdScaledVarForecast'].to_numpy()[np.where(anomalies_errors_ae_mod==True)], \n",
    "                alpha=0.8, color='lightgreen', s=150, label = \"Modified Z-score Anomalies AE\")\n",
    "    plt.scatter(np.where(anomalies_errors_se_mod==True), X_test['valueStdScaledVarForecast'].to_numpy()[np.where(anomalies_errors_se_mod==True)], \n",
    "                alpha=0.8, color='orange', s=50, label = \"Modified Z-score Anomalies SE\")    \n",
    "    plt.legend()    \n",
    "    figName = f\"Y_predict-1-step-anomalies-T_{T}-trial_{trial_fname}.png\"\n",
    "    plt.savefig(figName, transparent=False);\n",
    "    \n",
    "    n_step_metrics = {}    \n",
    "    for predict_ahead in [5, 10, 15, 30, 60, 90, 120]:\n",
    "        y_pred_n_steps = generate_nsteps_forecasts(X_test_2.to_numpy(), results_VAR, T, predict_ahead)\n",
    "        \n",
    "        X2 = np.array(y_pred_n_steps).reshape(-1,2)\n",
    "        XX2 = pd.DataFrame(X2, columns=['valueStdScaled', 'TimeLatencyStdScaled'])    \n",
    "        shape_dif = X_test.shape[0] - XX2.shape[0] \n",
    "        XX2_new = None\n",
    "        if shape_dif > 0:\n",
    "            XX2_new = expand_dataframe_with_nsteps(XX2, shape_dif)\n",
    "        elif shape_dif < 0:\n",
    "            XX2_new = XX2[0:X_test.shape[0]]\n",
    "        else:\n",
    "            XX2_new = XX2.copy()   \n",
    "            \n",
    "        XX2_new.set_index(X_test.index, inplace=True)\n",
    "        # These are the predictions predict_ahead steps at a time\n",
    "        X_test['valueStdScaledVarForecast2'] = XX2_new['valueStdScaled']\n",
    "        X_test['TimeLatencyStdScaledVarForecast2'] = XX2_new['TimeLatencyStdScaled']        \n",
    "\n",
    "        errors_ae2 = calculate_absolute_prediction_errors(X_test['valueStdScaled'].to_numpy(), X_test['valueStdScaledVarForecast2'].to_numpy())\n",
    "        anomalies_ae2 = calculate_3sigma_anomalies(errors_ae2)        \n",
    "        errors_se2 = calculate_squared_prediction_errors(X_test['valueStdScaled'].to_numpy(), X_test['valueStdScaledVarForecast2'].to_numpy())\n",
    "        anomalies_se2 = calculate_3sigma_anomalies(errors_se2)\n",
    "        anomalies_y_pred_nsteps_mod, z_scores_y_pred_nsteps_mod = calculate_modified_zscore_anomalies(X_test['valueStdScaledVarForecast2'].to_numpy())\n",
    "        anomalies_errors_ae2_mod, z_scores_errors_ae2_mod = calculate_modified_zscore_anomalies(errors_ae2)\n",
    "        anomalies_errors_se2_mod, z_scores_errors_se2_mod = calculate_modified_zscore_anomalies(errors_se2)\n",
    "        \n",
    "        anomalies_3sigma_y_pred_nsteps = calculate_3sigma_anomalies(X_test['valueStdScaledVarForecast2'].to_numpy())\n",
    "        anomalies_y_pred_nsteps, z_scores_y_pred_nsteps = calculate_zscore_anomalies(X_test['valueStdScaledVarForecast2'].to_numpy())\n",
    "        anomalies_errors_ae2, z_scores_errors_ae2 = calculate_zscore_anomalies(errors_ae2)\n",
    "        anomalies_errors_se2, z_scores_errors_se2 = calculate_zscore_anomalies(errors_se2)\n",
    "\n",
    "        crt_step_timeLatency = f'predict_ahead_{predict_ahead})_timeLatency'\n",
    "        crt_step_throughput = f'predict_ahead_{predict_ahead})_throughput'\n",
    "\n",
    "        aic = calculate_aic(len(X_test['TimeLatencyStdScaled']), \n",
    "                            mean_squared_error(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast2']),\n",
    "                            2)\n",
    "        \n",
    "        n_step_metrics[crt_step_timeLatency] = {'r2_nStep': r2_score(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast2']),\n",
    "                                                'mae_nStep': mean_absolute_error(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast2']),\n",
    "                                                'mape_nStep': mean_absolute_percentage_error(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast2']),\n",
    "                                                'mse_nStep': mean_squared_error(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast2']),\n",
    "                                                'pcc_nStep': np.corrcoef(X_test['TimeLatencyStdScaled'], X_test['TimeLatencyStdScaledVarForecast2'])[0,1],\n",
    "                                                'aic_nStep': aic}\n",
    "\n",
    "        aic = calculate_aic(len(X_test['valueStdScaled']), \n",
    "                            mean_squared_error(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast2']),\n",
    "                            2)\n",
    "\n",
    "        n_step_metrics[crt_step_throughput] = {'r2_nStep': r2_score(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast2']),\n",
    "                                               'mae_nStep': mean_absolute_error(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast2']),\n",
    "                                                'mape_nStep': mean_absolute_percentage_error(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast2']),\n",
    "                                                'mse_nStep': mean_squared_error(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast2']),\n",
    "                                                'pcc_nStep': np.corrcoef(X_test['valueStdScaled'], X_test['valueStdScaledVarForecast2'])[0,1],\n",
    "                                                'aic_nStep': aic}\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,15))        \n",
    "        plt.title(\"Predict Anomalies T=\" + str(T) + \" with predict \" + str(predict_ahead) + \" on \" + str(model_exp))\n",
    "        plt.plot(X_test['valueStdScaledVarForecast2'].to_numpy(),label=\"Predict \" + str(predict_ahead) + \"-step Forecast\", alpha=0.6, c='red', linewidth=3)\n",
    "        plt.plot(X_test['valueStdScaled'].to_numpy(),label=\"Original Data\", alpha=0.6, c='black')\n",
    "        plt.scatter(np.where(anomalies_ae2==True), X_test['valueStdScaledVarForecast2'].to_numpy()[np.where(anomalies_ae2==True)], alpha=0.8, color='green', s=350, label=\"Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_se2==True), X_test['valueStdScaledVarForecast2'].to_numpy()[np.where(anomalies_se2==True)], alpha=0.8, color='magenta', s=300, label = \"Anomalies SE\")\n",
    "        plt.scatter(np.where(anomalies_errors_ae2==True), X_test['valueStdScaledVarForecast2'].to_numpy()[np.where(anomalies_errors_ae2==True)], alpha=0.8, color='blue', s=250, label = \"Z-score Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_errors_se2==True), X_test['valueStdScaledVarForecast2'].to_numpy()[np.where(anomalies_errors_se2==True)], alpha=0.8, color='cyan', s=200, label = \"Z-score Anomalies SE\")\n",
    "        plt.scatter(np.where(anomalies_errors_ae2_mod==True), X_test['valueStdScaledVarForecast2'].to_numpy()[np.where(anomalies_errors_ae2_mod==True)], alpha=0.8, color='lime', s=150, label = \"Modified Z-score Anomalies AE\")\n",
    "        plt.scatter(np.where(anomalies_errors_se2_mod==True), X_test['valueStdScaledVarForecast2'].to_numpy()[np.where(anomalies_errors_se2_mod==True)], alpha=0.8, color='orange', s=50, label = \"Modified Z-score Anomalies SE\")        \n",
    "        plt.legend();    \n",
    "        figName = f\"Y-predict-anomalies-step-{predict_ahead}-with-T_{T}-trial-{trial_fname}.png\"\n",
    "        plt.savefig(figName, transparent=False)        \n",
    "\n",
    "    results[trial_fname] = {\"one_step_throughput\" : one_step_throughput,\n",
    "                            \"one_step_time_latency\" : one_step_timeLatency,\n",
    "                            \"n_step_metric\": n_step_metrics}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c22ba-00a8-44a2-9b68-747f0bf6f832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96e398-ece2-4ea4-8a42-ec16b1309e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in results.keys():\n",
    "    print(results[item]['one_step_throughput'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06796eb-07d6-456e-af68-9fd1bd65face",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-CPU",
   "language": "python",
   "name": "tf-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
